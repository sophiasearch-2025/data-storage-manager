# ğŸ—ï¸ Arquitectura del Sistema

El **Data Storage Manager** opera bajo una arquitectura de microservicios, diseÃ±ada para el procesamiento y almacenamiento asÃ­ncrono de grandes volÃºmenes de datos de noticias.

## 1. ğŸŒ Componentes Principales

El sistema se compone de servicios de aplicaciÃ³n desacoplados y una infraestructura de datos robusta:

### Aplicaciones (Microservicios)

* **API Ingestion**: API REST que actÃºa como la puerta de entrada, recibiendo el formato nativo del scraper.
* **Worker Indexer**: Procesa las noticias recibidas, incluyendo la tarea crÃ­tica de parsear fechas espaÃ±olas y guardar la informaciÃ³n en **PostgreSQL**.
* **Worker Sync**: Responsable de sincronizar las noticias desde **PostgreSQL** a **Elasticsearch** para habilitar la bÃºsqueda rÃ¡pida.

### Infraestructura de Datos

* **PostgreSQL**: Base de datos relacional utilizada como la **fuente Ãºnica de verdad** para el almacenamiento persistente.
* **Elasticsearch**: Motor de bÃºsqueda optimizado para consultas rÃ¡pidas y de texto completo.
* **RabbitMQ**: Cola de mensajes que garantiza el procesamiento asÃ­ncrono y la resiliencia entre los servicios.

---

## 2. ğŸŒŠ Flujo de Datos (AsÃ­ncrono)

El procesamiento de una noticia es completamente asÃ­ncrono, lo que garantiza que la API de ingesta responda rÃ¡pidamente y el procesamiento se realice sin bloquear al cliente.
## Flujo de Datos

El flujo de una noticia desde la ingesta hasta su almacenamiento y bÃºsqueda es el siguiente:

1. **Ingesta**: El `Cliente` envÃ­a la noticia por HTTP a la **API Ingestion**.
2. **Encolado**: La **API Ingestion** pone el mensaje en la cola `ingestion_queue` de RabbitMQ.
3. **IndexaciÃ³n**: El **Worker Indexer** lee de `ingestion_queue` y escribe la noticia en **PostgreSQL**.
4. **SincronizaciÃ³n (AsÃ­ncrona)**: DespuÃ©s de la escritura, se genera un evento que se envÃ­a a la cola `sync_queue` de RabbitMQ.
5. **BÃºsqueda**: El **Worker Sync** lee de `sync_queue` y escribe o actualiza el documento en **Elasticsearch**.

```
Cliente â†’ API Ingestion â†’ RabbitMQ (ingestion_queue)
                              â†“
                        Worker Indexer â†’ PostgreSQL
                              â†“
                    RabbitMQ (sync_queue)
                              â†“
                        Worker Sync â†’ Elasticsearch
```

### Componentes

- **PostgreSQL**: Base de datos relacional para almacenamiento persistente
- **Elasticsearch**: Motor de bÃºsqueda para consultas rÃ¡pidas
- **RabbitMQ**: Cola de mensajes para procesamiento asÃ­ncrono
- **API Ingestion**: API REST para recibir noticias
- **Worker Indexer**: Procesa noticias y las guarda en PostgreSQL
- **Worker Sync**: Sincroniza noticias de PostgreSQL a Elasticsearch

### Estructura del Proyecto

```
.
â”œâ”€â”€ api-ingestion/          # API REST para ingesta
â”œâ”€â”€ workers/
â”‚   â”œâ”€â”€ common/             # ConfiguraciÃ³n compartida
â”‚   â”œâ”€â”€ indexer/            # Worker de indexaciÃ³n a Postgres
â”‚   â””â”€â”€ sync/               # Worker de sincronizaciÃ³n a ES
â”œâ”€â”€ database/
â”‚   â””â”€â”€ migrations/         # Migraciones SQL
â”œâ”€â”€ elasticsearch/
â”‚   â””â”€â”€ init/               # Scripts de inicializaciÃ³n
â””â”€â”€ docker-compose.yml      # OrquestaciÃ³n de servicios
```
---

## 4. ğŸ—ƒï¸ Detalle de Componentes Clave

### API Ingestion - Modelo de Datos

La API recibe el formato nativo del scraper y lo mapea al siguiente DTO (Data Transfer Object) en Go:

```go
type NewsRequest struct {
    URL            string   `json:"url"`
    Titulo         string   `json:"titulo"`
    Fecha          string   `json:"fecha"`           // Formato espaÃ±ol
    Tags           []string `json:"tags"`
    Autor          string   `json:"autor"`
    DescAutor      string   `json:"desc_autor"`
    Abstract       string   `json:"abstract"`
    Cuerpo         string   `json:"cuerpo"`
    Multimedia     []string `json:"multimedia"`
    TipoMultimedia string   `json:"tipo_multimedia"`
}
```
### Worker Indexer (Logica de Procesamiento)

Este worker contiene la logica clave de transformacion y validacion:
- **Parser de fechas**: Tiene un parser de fechas espaÃ±olas integrado.
- **ExtracciÃ³n de Metadata**: Realiza la auto-extracciÃ³n del medio desde la URL.
- **GestiÃ³n de Tags**: Se encarga de la creaciÃ³n automÃ¡tica de tags y su relaciÃ³n many-to-many.
- **DetecciÃ³n de Duplicados**: Utiliza un Hash SHA256 de la URL normalizada para prevenir ingestas duplicadas.